{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469e1e5-b7ac-4513-a3e6-b738d0d875a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyMuPDF\n",
    "!pip install scispacy\n",
    "!pip install transformers\n",
    "!pip install spacy\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2734b8-9d28-46ed-b399-d059fce2020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import fitz  # PyMuPDF for PDF processing\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6a5e7-6660-4442-a5ec-86e74451cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 1: PDF Text Extraction ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ed8d2-af4d-452e-98f3-fa477cd5adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using PyMuPDF (fitz).\n",
    "    \n",
    "    :param pdf_path: Path to the PDF file\n",
    "    :return: Extracted text as a string\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)  # Open the PDF file\n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc.load_page(page_num)  # Load each page\n",
    "            text += page.get_text(\"text\")  # Extract text from the page\n",
    "        doc.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b695a-0102-4e28-93c7-ad0a778366d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 2: Medical Named Entity Recognition (NER) ----\n",
    "# Load the SciSpacy model for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca956fc-6358-44b6-9814-461d287bf621",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_sci_md\")  # You can replace with 'en_ner_bc5cdr_md' for better medical entity recognition\n",
    "\n",
    "def extract_medical_entities(text):\n",
    "    \"\"\"\n",
    "    Extracts medical entities (diseases, symptoms, medications) from text using SciSpacy NER model.\n",
    "    \n",
    "    :param text: Input text (medical records)\n",
    "    :return: List of extracted entities\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['DISEASE', 'SYMPTOM', 'DRUG']:  # Adjust for relevant entity types\n",
    "            entities.append((ent.text, ent.label_))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31972f62-8b4e-43e1-9628-905fa3a1d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 3: Summarization of Medical Text ----\n",
    "# Summarization pipeline from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c9e80-9209-4159-9c5f-4a677f7cc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_medical_text(text, max_length=200):\n",
    "    \"\"\"\n",
    "    Summarizes long medical text using a transformer-based model.\n",
    "    \n",
    "    :param text: Input medical text\n",
    "    :param max_length: Maximum length of the summary\n",
    "    :return: Summarized text\n",
    "    \"\"\"\n",
    "    # Hugging Face models require shorter text chunks, so we will split if necessary\n",
    "    text_chunks = [text[i:i + 1000] for i in range(0, len(text), 1000)]  # Splitting long text into 1000 token chunks\n",
    "    summary = \"\"\n",
    "    for chunk in text_chunks:\n",
    "        summary += summarizer(chunk, max_length=max_length, min_length=50, do_sample=False)[0]['summary_text']\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7aee4-faa9-41a5-889e-44f3b10e9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 4: Relevance Matching ----\n",
    "# Load pre-trained sentence embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2c30f-2928-445a-95be-9040b3de7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def match_relevant_info_to_case(medical_summary, court_case_prompt):\n",
    "    \"\"\"\n",
    "    Matches the medical summary to the court case prompt based on text similarity.\n",
    "    \n",
    "    :param medical_summary: Summarized medical information\n",
    "    :param court_case_prompt: Court case description or prompt\n",
    "    :return: Relevance score (cosine similarity)\n",
    "    \"\"\"\n",
    "    # Get sentence embeddings for both the medical summary and the court case prompt\n",
    "    summary_embedding = embedding_model.encode(medical_summary, convert_to_tensor=True)\n",
    "    prompt_embedding = embedding_model.encode(court_case_prompt, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarity between the two embeddings\n",
    "    similarity_score = util.pytorch_cos_sim(summary_embedding, prompt_embedding)\n",
    "    return similarity_score.item()  # Convert to a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c7077-e349-4d46-828b-ba2a1905271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STEP 5: Putting it All Together ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bed394-b1e5-4ea6-b8ce-811e6b4e3cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_medical_pdf_for_court_case(pdf_path, court_case_prompt):\n",
    "    \"\"\"\n",
    "    Main function to process a medical PDF for relevant information related to a court case.\n",
    "    \n",
    "    :param pdf_path: Path to the medical PDF\n",
    "    :param court_case_prompt: Court case prompt describing the relevant details\n",
    "    :return: Final summarized and relevant information\n",
    "    \"\"\"\n",
    "    # Step 1: Extract text from the PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Step 2: Extract medical entities from the text\n",
    "    medical_entities = extract_medical_entities(pdf_text)\n",
    "    \n",
    "    # Step 3: Summarize the extracted medical text\n",
    "    summarized_text = summarize_medical_text(pdf_text)\n",
    "    \n",
    "    # Step 4: Match the summarized medical data to the court case prompt\n",
    "    relevance_score = match_relevant_info_to_case(summarized_text, court_case_prompt)\n",
    "\n",
    "    # Final output\n",
    "    return {\n",
    "        \"summarized_text\": summarized_text,\n",
    "        \"medical_entities\": medical_entities,\n",
    "        \"relevance_score\": relevance_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e887a-d955-413d-b560-760e99323ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Example Usage ----\n",
    "pdf_path = \"path_to_medical_pdf.pdf\"  # Replace with the path to the medical PDF you want to analyze\n",
    "court_case_prompt = \"The patient is involved in a car accident case and is suffering from multiple fractures and PTSD.\"\n",
    "\n",
    "# Run the processing function\n",
    "result = process_medical_pdf_for_court_case(pdf_path, court_case_prompt)\n",
    "\n",
    "# Print results\n",
    "print(\"Summarized Medical Information:\")\n",
    "print(result['summarized_text'])\n",
    "print(\"\\nExtracted Medical Entities:\")\n",
    "print(result['medical_entities'])\n",
    "print(\"\\nRelevance Score to the Court Case:\")\n",
    "print(result['relevance_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf95af6-ab4f-466c-b9c0-4ba7e50a5387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517caf2-e595-468f-b63d-dc46fd13430b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6cc6d-ed3d-424f-bd05-fa6476c0a95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e4b97-4642-42c3-b127-f6367b80a3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc169c-c024-4f9a-907c-4e52846d9187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
